{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mask_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS95fW-bCMbC"
      },
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "#upload a file named \"kaggle.json\" given in repository\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBCpbNc6vw1i"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj9SBruUwQS1"
      },
      "source": [
        "#download mask-detection dataset\n",
        "!kaggle datasets download -d shanmukh05/mask-detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cbjVkltLqRM"
      },
      "source": [
        "#import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import datetime\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZKvbYcsLy4r"
      },
      "source": [
        "#path of downloaded zipfile (changes accordingly)\n",
        "path = \"/content/mask-detection.zip\"\n",
        "zipref = zipfile.ZipFile(path, \"r\")\n",
        "zipref.extractall(\"/content/\")\n",
        "zipref.close()\n",
        "\n",
        "data_dir = \"/content/mask_detection/\"\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "image_count = len(list(data_dir.glob(\"*/*.jpg\")))\n",
        "print(image_count)\n",
        "no = list(data_dir.glob(\"no/*\"))\n",
        "PIL.Image.open(str(no[6]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyHT2oiKL_QS"
      },
      "source": [
        "batch_size = 32\n",
        "height = 300\n",
        "width = 300\n",
        "\n",
        "#prepare training data\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.1,\n",
        "    subset = \"training\",\n",
        "    seed =123,\n",
        "    image_size =(height,width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "#prepare validation data\n",
        "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.1,\n",
        "    subset = \"validation\",\n",
        "    seed=123,\n",
        "    image_size=(height,width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "classes = train_data.class_names\n",
        "print(classes)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_data.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(classes[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "images = images.numpy().astype(\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohiqgiE_Nice"
      },
      "source": [
        "#load tensorboard necessities\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1pFJRAfXr3i"
      },
      "source": [
        "#remove the log folder if any present\n",
        "!rm -rf ./logs/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6WGra-0N_0Q"
      },
      "source": [
        "#visualizing training images using TensorBoard\n",
        "\n",
        "logdir = \"logs/train_data/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\",images,max_outputs=32,step=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7pJ47WSNygS"
      },
      "source": [
        "#visualizing training images using TensorBoard\n",
        "\n",
        "%tensorboard --logdir logs/train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFTDkQpFOFh4"
      },
      "source": [
        "#Hyperparametr tuning using TensorBoard\n",
        "\n",
        "H_DROPOUT = hp.HParam(\"dropout\",hp.RealInterval(0.2,0.5))\n",
        "H_OPTIMIZER =   hp.HParam(\"optimizer\",hp.Discrete([\"adam\"]))\n",
        "METRIC = \"accuracy\" \n",
        "\n",
        "with tf.summary.create_file_writer(\"logs/hparam_tuning\").as_default():\n",
        "  hp.hparams_config(\n",
        "      hparams = [H_DROPOUT,H_OPTIMIZER],\n",
        "      metrics = [hp.Metric(METRIC,display_name=\"Accuracy\")]\n",
        "  )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhrdqy26VCbQ"
      },
      "source": [
        "#visualizing accuracy,weights(bias,kernel weights) in tensorboard\n",
        "\n",
        "logdir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdxwqURKuqOC"
      },
      "source": [
        "#optimize the input of data while running\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_data = val_data.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "\n",
        "#data augumentation\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\",input_shape=(height, width,3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "#define the model\n",
        "def train_model(hparams):\n",
        "  model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(hparams[H_DROPOUT]),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(32, activation='relu'),\n",
        "  layers.Dense(1,activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=hparams[H_OPTIMIZER],\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  epochs=20\n",
        "  logdir = \"logs/hparam_tuning\"\n",
        "  history=model.fit(\n",
        "  train_data,\n",
        "  validation_data=val_data,\n",
        "  epochs=epochs,\n",
        "  verbose=1)\n",
        "  accuracy = history.history[\"val_accuracy\"]\n",
        "  return accuracy[epochs-1]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEgBV34iP9mS"
      },
      "source": [
        "#For each run, log an hparams summary with the hyperparameters and final accuracy\n",
        "\n",
        "def run(dir,hparams):\n",
        "  with tf.summary.create_file_writer(dir).as_default():\n",
        "    hp.hparams(hparams)\n",
        "    accuracy = train_model(hparams)\n",
        "    tf.summary.scalar(METRIC,accuracy,step=1)\n",
        "  return accuracy"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svFkukDnSGzz"
      },
      "source": [
        "#Start runs and log them all under one parent directory\n",
        "\n",
        "session_num = 0\n",
        "best_dropout = 0\n",
        "best_optimizer = None\n",
        "high_acc =0\n",
        "for dropout_rate in (H_DROPOUT.domain.min_value, H_DROPOUT.domain.max_value):\n",
        "  for optimizer in H_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          H_DROPOUT: dropout_rate,\n",
        "          H_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      accuracy=run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      if accuracy > high_acc:\n",
        "        high_acc=accuracy\n",
        "        print(high_acc)\n",
        "        best_dropout = hparams[H_DROPOUT]\n",
        "        best_optimizer = hparams[H_OPTIMIZER]\n",
        "      session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKL2edZSu8H"
      },
      "source": [
        "%tensorboard --logdir logs/hparam_tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl8SS-xPYFhU"
      },
      "source": [
        "#visualizing accuracy,weights(bias,kernel weights) in tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN8NIKktTWjY"
      },
      "source": [
        "#finding the best model\n",
        "print(\"Best Dropout parameter: \",best_dropout)\n",
        "print(\"Best optimizer: \",best_optimizer)\n",
        "model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(best_dropout),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(32, activation='relu'),\n",
        "  layers.Dense(1,activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer=best_optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "epochs=20\n",
        "  \n",
        "history=model.fit(\n",
        "  train_data,\n",
        "  validation_data=val_data,\n",
        "  epochs=epochs,\n",
        "  verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORsq6gZZMO6Z"
      },
      "source": [
        "#visualizing the accuracy and loss of train and validation dataset \n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay4krA26NRYk"
      },
      "source": [
        "#predict for unseen multiple images\n",
        "ls = os.listdir(\"/content/prediction/\")\n",
        "path = \"/content/prediction/\"\n",
        "#ls.remove('.ipynb_checkpoints')\n",
        "img_arr=[]\n",
        "predictions =[]\n",
        "scores =[]\n",
        "for j,i in enumerate(ls):\n",
        "  img = tf.keras.preprocessing.image.load_img(\n",
        "      path+i,target_size = (height,width)\n",
        "  )\n",
        "  arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img_arr.append(arr)\n",
        "  arr = tf.expand_dims(arr,0)\n",
        "  pred = model.predict(arr)\n",
        "  prediction=pred[0][0]\n",
        "  if prediction <0.5:\n",
        "    predictions.append(0)\n",
        "    scores.append(100*(1-prediction))\n",
        "  else:\n",
        "    predictions.append(1)\n",
        "    scores.append(100*prediction)\n",
        "scores = [round(i,2) for i in scores]\n",
        "txt = [\"didn't wear mask \",\"wore mask \"]\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(25):\n",
        "  ax = plt.subplot(5,5, i + 1)\n",
        "  plt.imshow(img_arr[i].astype(\"uint8\"))\n",
        "  text = str(txt[predictions[i]])+\"(\"+str(scores[i])+\"% acc)\"\n",
        "  plt.title(text)\n",
        "  plt.axis(\"off\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XsLce1Mpij"
      },
      "source": [
        "#for single unseen image\n",
        "path = \"/content/prediction/11.jpg\"\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(\n",
        "    path,target_size = (height,width)\n",
        ")\n",
        "\n",
        "img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_arr = tf.expand_dims(img_arr,0)\n",
        "prediction = model.predict(img_arr)\n",
        "print(prediction[0][0])\n",
        "score = prediction[0]\n",
        "if score<0.5:\n",
        "  print(\"The person in the given image didn't wear a mask\")\n",
        "else:\n",
        "  print(\"The person in the image wore mask\")\n",
        "\n",
        "PIL.Image.open(str(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8BB5ZhTujkp"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60a0f9Xs9sb"
      },
      "source": [
        "#outputs of different layers for training data\n",
        "layer1= model.get_layer(\"rescaling_17\")\n",
        "layer2 = model.get_layer(\"conv2d_51\")\n",
        "layer3 = model.get_layer(\"max_pooling2d_51\")\n",
        "layer4 = model.get_layer(\"conv2d_52\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "for img,label in train_data.take(1):\n",
        "  out1 = layer1(img)\n",
        "  out2 = layer2(out1)\n",
        "  out3= layer3(out2)\n",
        "  out4 = layer4(out3)\n",
        "  for i in range(1):\n",
        "    img_arr = tf.keras.preprocessing.image.img_to_array(img[i])\n",
        "    img_arr = tf.expand_dims(img_arr,0)\n",
        "    pred = model.predict(img_arr)*100\n",
        "    pred =round(pred[0][0],2)\n",
        "    ax = plt.subplot(3,4,1+3*i)\n",
        "    plt.imshow(img[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(str(pred))\n",
        "    ax = plt.subplot(3,4,2+3*i)\n",
        "    im1 = np.sum(out2[i],axis=2)\n",
        "    plt.imshow(im1.astype(\"uint8\"))\n",
        "    plt.title(str(pred))\n",
        "    ax = plt.subplot(3,4,3+3*i)\n",
        "    im2 = np.sum(out3[i],axis=2)\n",
        "    plt.imshow(im2.astype(\"uint8\"))\n",
        "    plt.title(str(pred))\n",
        "    ax = plt.subplot(3,4,4+3*i)\n",
        "    im3 = np.sum(out4[i],axis=2)\n",
        "    plt.imshow(im3.astype(\"uint8\"))\n",
        "    plt.title(str(pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWoIx_Vy2BYA"
      },
      "source": [
        "#outputs of different layers for unseen images\n",
        "path = \"/content/prediction/25.jpg\"\n",
        "img = tf.keras.preprocessing.image.load_img(\n",
        "    path,target_size = (height,width)\n",
        ")\n",
        "img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_arr = tf.expand_dims(img_arr,0)\n",
        "pred = model.predict(img_arr)*100\n",
        "pred =round(pred[0][0],2)\n",
        "\n",
        "#names of the layers will be changed as per model.summary() output\n",
        "\n",
        "layer1= model.get_layer(\"rescaling_17\")\n",
        "layer2 = model.get_layer(\"conv2d_51\")\n",
        "layer3 = model.get_layer(\"max_pooling2d_51\")\n",
        "layer4 = model.get_layer(\"conv2d_52\")\n",
        "layer5 = model.get_layer(\"max_pooling2d_52\")\n",
        "layer6 = model.get_layer(\"conv2d_53\")\n",
        "layer7 = model.get_layer(\"max_pooling2d_53\")\n",
        "layer8 = model.get_layer(\"dropout_17\")\n",
        "\n",
        "out1 = layer1(img_arr)\n",
        "out2 = layer2(out1)\n",
        "out3 = layer3(out2)\n",
        "out4 = layer4(out3)\n",
        "out5 = layer5(out4)\n",
        "out6 = layer6(out5)\n",
        "out7 = layer7(out6)\n",
        "out8 = layer8(out7)\n",
        "num =5\n",
        "plt.figure(figsize=(30,30))\n",
        "ax = plt.subplot(1,num,1)\n",
        "plt.imshow(img_arr[0].numpy().astype(\"uint8\"))\n",
        "plt.title(str(pred))\n",
        "ax = plt.subplot(1,num,2)\n",
        "plt.imshow(np.sum(out2[0],axis=2).astype(\"uint8\"))\n",
        "plt.title(str(pred))\n",
        "ax = plt.subplot(1,num,3)\n",
        "plt.imshow(np.sum(out3[0],axis=2).astype(\"uint8\"))\n",
        "plt.title(str(pred))\n",
        "ax = plt.subplot(1,num,4)\n",
        "plt.imshow(np.sum(out6[0],axis=2).astype(\"uint8\"))\n",
        "plt.title(str(pred))\n",
        "ax = plt.subplot(1,num,5)\n",
        "plt.imshow(np.sum(out8[0],axis=2).astype(\"uint8\"))\n",
        "plt.title(str(pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13VSKTjsUrDm"
      },
      "source": [
        "#outputs of various filter in given convolution layer\n",
        "img_arr = out6[0].numpy()\n",
        "x,y,z = img_arr.shape\n",
        "arr = img_arr.reshape(x*y*z,1)*255\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(16):\n",
        "  ax = plt.subplot(5,4,i+1)\n",
        "  plt.imshow(arr[x*y*i:x*y*i+x*y].reshape(x,y).astype(\"uint8\"))\n",
        "  plt.title(str(pred))\n",
        "ax = plt.subplot(5,4,17)\n",
        "plt.imshow(np.sum(img_arr,axis=2).astype(\"uint8\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}